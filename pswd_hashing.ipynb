{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pswd_hashing.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOdhXEHlgpz9LfKeVnq3e2Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harix1606/human-hashing/blob/master/pswd_hashing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-u3_w6J9AGy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b0d61d86-ade7-4fa8-c4fd-59137fed6e30"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers.recurrent import LSTM\n",
        "import numpy as np\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-gMFEgB_Pty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "1026f30f-da98-4444-cf08-d9ae63edcbb8"
      },
      "source": [
        "pswds = []\n",
        "with open ('cue_pin.csv','r') as csvFile:\n",
        "    read = csv.reader(csvFile, delimiter = ',')\n",
        "    for rows in read:\n",
        "        pswds.append(rows[0])\n",
        "\n",
        "pswds = pswds[1:]\n",
        "print (pswds)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ampoesterfee', 'dskldsreedog', 'autwom6org', 'aecsicjuioyc', 'dskldsreedog', 'ffeeepeatrla', 'otseocarlddoexis', 'csebroeraecu', 'alafalcefafe', 'ficttelivsin', 'Azznflnflthe', 'nsoutiemosro', 'nvinme', 'digitalduster57', 'oaratberanch', 'oRaWhaRamina', 'Iroowbrncboo', 'sibsensponeo', 'mazo1dorm2laniro3ormebe4', 'aptl5105', 'Olarvoolarvo', 'setrsedarenc', 'epiocollorth', 'Olarvoolarvo', 'ndodogpenlca', 'mazo1dorm2laniro3ormebe4', 'Errnssryaeep', 'Dpuarkairabl', 'ikswofsairbe', 'mkidlps', 'Ifinorgenhel', 'Ratatmatmamt', 'ymuearneyrhe', 'eraerbtroeer', 'redtysdardou', 'Serpplalaign', 'nymelfindshp', 'digitaldesign58', 'oaratberanch', 'foofballerys', 'Pleeabuicarw', 'Bleblehorabl', 'elberrseseel', 'cheuittbicuit', 'ficobvtemary', 'Entylogpatsf', 'footcransery', 'footcransery', 'Gootride', 'KAUNDIPENOTT', 'Ardrseaptnnscebo', 'apprryeahmilcat', 'hirtspchaabl', 'u1eu', 'Pl@s$nky', 'feista 0235', 'getdogticeti', 'diesperfar', 'friquerietht', 'tuailauanlac5831', 'verrroosever', 'rryhorqwbott', 'irpappocolec', 'ev6sfgh4gv3q', 'irshaifapssa', 'getsadticome', 'prarybpratop', 'Pplppllloepi', 'eppepermepep']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj3SP9a2CEbj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a2923aa9-50d3-4e0c-9849-d2acbf537e60"
      },
      "source": [
        "#Padding the passwords:\n",
        "\n",
        "longest_pswd = 0\n",
        "for words in pswds:\n",
        "    if len(words) > longest_pswd:\n",
        "        longest_pswd = len(words)\n",
        "\n",
        "padded_pswds = []\n",
        "for words in pswds: \n",
        "    remaining = longest_pswd - len(words)\n",
        "    new_words = '0'*remaining + words\n",
        "    padded_pswds.append(new_words)\n",
        "\n",
        "print (padded_pswds)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['000000000000ampoesterfee', '000000000000dskldsreedog', '00000000000000autwom6org', '000000000000aecsicjuioyc', '000000000000dskldsreedog', '000000000000ffeeepeatrla', '00000000otseocarlddoexis', '000000000000csebroeraecu', '000000000000alafalcefafe', '000000000000ficttelivsin', '000000000000Azznflnflthe', '000000000000nsoutiemosro', '000000000000000000nvinme', '000000000digitalduster57', '000000000000oaratberanch', '000000000000oRaWhaRamina', '000000000000Iroowbrncboo', '000000000000sibsensponeo', 'mazo1dorm2laniro3ormebe4', '0000000000000000aptl5105', '000000000000Olarvoolarvo', '000000000000setrsedarenc', '000000000000epiocollorth', '000000000000Olarvoolarvo', '000000000000ndodogpenlca', 'mazo1dorm2laniro3ormebe4', '000000000000Errnssryaeep', '000000000000Dpuarkairabl', '000000000000ikswofsairbe', '00000000000000000mkidlps', '000000000000Ifinorgenhel', '000000000000Ratatmatmamt', '000000000000ymuearneyrhe', '000000000000eraerbtroeer', '000000000000redtysdardou', '000000000000Serpplalaign', '000000000000nymelfindshp', '000000000digitaldesign58', '000000000000oaratberanch', '000000000000foofballerys', '000000000000Pleeabuicarw', '000000000000Bleblehorabl', '000000000000elberrseseel', '00000000000cheuittbicuit', '000000000000ficobvtemary', '000000000000Entylogpatsf', '000000000000footcransery', '000000000000footcransery', '0000000000000000Gootride', '000000000000KAUNDIPENOTT', '00000000Ardrseaptnnscebo', '000000000apprryeahmilcat', '000000000000hirtspchaabl', '00000000000000000000u1eu', '0000000000000000Pl@s$nky', '0000000000000feista 0235', '000000000000getdogticeti', '00000000000000diesperfar', '000000000000friquerietht', '00000000tuailauanlac5831', '000000000000verrroosever', '000000000000rryhorqwbott', '000000000000irpappocolec', '000000000000ev6sfgh4gv3q', '000000000000irshaifapssa', '000000000000getsadticome', '000000000000prarybpratop', '000000000000Pplppllloepi', '000000000000eppepermepep']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKM8v5eTJhg4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8dd842ab-3686-4f79-82ab-60314451f2c4"
      },
      "source": [
        "#The vocabulary of the passwords\n",
        "vocab = list({l for word in padded_pswds for l in word})\n",
        "len_of_vocab = len(vocab)\n",
        "\n",
        "# Mappings of character to index number and vice versa\n",
        "index_to_char = {}\n",
        "char_to_index = {}\n",
        "for i, char in enumerate(vocab):\n",
        "    index_to_char[i] = char\n",
        "    char_to_index[char] = i\n",
        "\n",
        "print (char_to_index)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'$': 0, 'i': 1, 'W': 2, 'S': 3, 'q': 4, 'z': 5, ' ': 6, 'B': 7, '8': 8, 'o': 9, 'j': 10, 'N': 11, 'T': 12, '2': 13, 'D': 14, 'G': 15, 'R': 16, '4': 17, '1': 18, 'w': 19, 't': 20, 'h': 21, 'k': 22, 'l': 23, 'y': 24, 'a': 25, '0': 26, '7': 27, '3': 28, 'e': 29, 'I': 30, '5': 31, 'c': 32, 'n': 33, 'K': 34, 'P': 35, 'm': 36, 'v': 37, 'p': 38, 'x': 39, 'A': 40, 'U': 41, '@': 42, 'E': 43, '6': 44, 'g': 45, 'u': 46, 'O': 47, 'd': 48, 'b': 49, 's': 50, 'r': 51, 'f': 52}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6llIFZsERoql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "62dad936-3eab-4fa8-ea44-2d1a3d74d8c5"
      },
      "source": [
        "#password sequences must be encoded as a sequence of integers.\n",
        "\n",
        "sequences = []\n",
        "for words in padded_pswds:\n",
        "    encoded_seq = [char_to_index[letters] for letters in words]\n",
        "    sequences.append(encoded_seq)\n",
        "\n",
        "print (sequences)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 36, 38, 9, 29, 50, 20, 29, 51, 52, 29, 29], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 48, 50, 22, 23, 48, 50, 51, 29, 29, 48, 9, 45], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 46, 20, 19, 9, 36, 44, 9, 51, 45], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 29, 32, 50, 1, 32, 10, 46, 1, 9, 24, 32], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 48, 50, 22, 23, 48, 50, 51, 29, 29, 48, 9, 45], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 52, 52, 29, 29, 29, 38, 29, 25, 20, 51, 23, 25], [26, 26, 26, 26, 26, 26, 26, 26, 9, 20, 50, 29, 9, 32, 25, 51, 23, 48, 48, 9, 29, 39, 1, 50], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 32, 50, 29, 49, 51, 9, 29, 51, 25, 29, 32, 46], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 23, 25, 52, 25, 23, 32, 29, 52, 25, 52, 29], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 52, 1, 32, 20, 20, 29, 23, 1, 37, 50, 1, 33], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 40, 5, 5, 33, 52, 23, 33, 52, 23, 20, 21, 29], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 33, 50, 9, 46, 20, 1, 29, 36, 9, 50, 51, 9], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 33, 37, 1, 33, 36, 29], [26, 26, 26, 26, 26, 26, 26, 26, 26, 48, 1, 45, 1, 20, 25, 23, 48, 46, 50, 20, 29, 51, 31, 27], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 9, 25, 51, 25, 20, 49, 29, 51, 25, 33, 32, 21], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 9, 16, 25, 2, 21, 25, 16, 25, 36, 1, 33, 25], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 30, 51, 9, 9, 19, 49, 51, 33, 32, 49, 9, 9], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 50, 1, 49, 50, 29, 33, 50, 38, 9, 33, 29, 9], [36, 25, 5, 9, 18, 48, 9, 51, 36, 13, 23, 25, 33, 1, 51, 9, 28, 9, 51, 36, 29, 49, 29, 17], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 38, 20, 23, 31, 18, 26, 31], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 47, 23, 25, 51, 37, 9, 9, 23, 25, 51, 37, 9], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 50, 29, 20, 51, 50, 29, 48, 25, 51, 29, 33, 32], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 29, 38, 1, 9, 32, 9, 23, 23, 9, 51, 20, 21], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 47, 23, 25, 51, 37, 9, 9, 23, 25, 51, 37, 9], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 33, 48, 9, 48, 9, 45, 38, 29, 33, 23, 32, 25], [36, 25, 5, 9, 18, 48, 9, 51, 36, 13, 23, 25, 33, 1, 51, 9, 28, 9, 51, 36, 29, 49, 29, 17], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 43, 51, 51, 33, 50, 50, 51, 24, 25, 29, 29, 38], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 14, 38, 46, 25, 51, 22, 25, 1, 51, 25, 49, 23], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 1, 22, 50, 19, 9, 52, 50, 25, 1, 51, 49, 29], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 36, 22, 1, 48, 23, 38, 50], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 30, 52, 1, 33, 9, 51, 45, 29, 33, 21, 29, 23], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 16, 25, 20, 25, 20, 36, 25, 20, 36, 25, 36, 20], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 24, 36, 46, 29, 25, 51, 33, 29, 24, 51, 21, 29], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 29, 51, 25, 29, 51, 49, 20, 51, 9, 29, 29, 51], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 51, 29, 48, 20, 24, 50, 48, 25, 51, 48, 9, 46], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 3, 29, 51, 38, 38, 23, 25, 23, 25, 1, 45, 33], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 33, 24, 36, 29, 23, 52, 1, 33, 48, 50, 21, 38], [26, 26, 26, 26, 26, 26, 26, 26, 26, 48, 1, 45, 1, 20, 25, 23, 48, 29, 50, 1, 45, 33, 31, 8], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 9, 25, 51, 25, 20, 49, 29, 51, 25, 33, 32, 21], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 52, 9, 9, 52, 49, 25, 23, 23, 29, 51, 24, 50], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 35, 23, 29, 29, 25, 49, 46, 1, 32, 25, 51, 19], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 7, 23, 29, 49, 23, 29, 21, 9, 51, 25, 49, 23], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 29, 23, 49, 29, 51, 51, 50, 29, 50, 29, 29, 23], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 32, 21, 29, 46, 1, 20, 20, 49, 1, 32, 46, 1, 20], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 52, 1, 32, 9, 49, 37, 20, 29, 36, 25, 51, 24], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 43, 33, 20, 24, 23, 9, 45, 38, 25, 20, 50, 52], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 52, 9, 9, 20, 32, 51, 25, 33, 50, 29, 51, 24], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 52, 9, 9, 20, 32, 51, 25, 33, 50, 29, 51, 24], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 15, 9, 9, 20, 51, 1, 48, 29], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 34, 40, 41, 11, 14, 30, 35, 43, 11, 47, 12, 12], [26, 26, 26, 26, 26, 26, 26, 26, 40, 51, 48, 51, 50, 29, 25, 38, 20, 33, 33, 50, 32, 29, 49, 9], [26, 26, 26, 26, 26, 26, 26, 26, 26, 25, 38, 38, 51, 51, 24, 29, 25, 21, 36, 1, 23, 32, 25, 20], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 21, 1, 51, 20, 50, 38, 32, 21, 25, 25, 49, 23], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 46, 18, 29, 46], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 35, 23, 42, 50, 0, 33, 22, 24], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 52, 29, 1, 50, 20, 25, 6, 26, 13, 28, 31], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 45, 29, 20, 48, 9, 45, 20, 1, 32, 29, 20, 1], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 48, 1, 29, 50, 38, 29, 51, 52, 25, 51], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 52, 51, 1, 4, 46, 29, 51, 1, 29, 20, 21, 20], [26, 26, 26, 26, 26, 26, 26, 26, 20, 46, 25, 1, 23, 25, 46, 25, 33, 23, 25, 32, 31, 8, 28, 18], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 37, 29, 51, 51, 51, 9, 9, 50, 29, 37, 29, 51], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 51, 51, 24, 21, 9, 51, 4, 19, 49, 9, 20, 20], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 1, 51, 38, 25, 38, 38, 9, 32, 9, 23, 29, 32], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 29, 37, 44, 50, 52, 45, 21, 17, 45, 37, 28, 4], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 1, 51, 50, 21, 25, 1, 52, 25, 38, 50, 50, 25], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 45, 29, 20, 50, 25, 48, 20, 1, 32, 9, 36, 29], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 38, 51, 25, 51, 24, 49, 38, 51, 25, 20, 9, 38], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 35, 38, 23, 38, 38, 23, 23, 23, 9, 29, 38, 1], [26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 29, 38, 38, 29, 38, 29, 51, 36, 29, 38, 29, 38]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlR1ZjWaSwEG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4dc9648d-76b8-483c-bf21-b8f4a9360958"
      },
      "source": [
        "#Splitting into input and output\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:,:-1], sequences[:,-1]\n",
        "\n",
        "sequences = [to_categorical(x, num_classes=len_of_vocab) for x in X]\n",
        "X = np.array(sequences)\n",
        "y = to_categorical(y, num_classes=len_of_vocab)\n",
        "\n",
        "y"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK7RMYh5gY6_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "7df11c21-fcee-434d-9faf-75854aabb991"
      },
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(LSTM(70, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dense(len_of_vocab, activation='softmax'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_6 (LSTM)                (None, 70)                34720     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 53)                3763      \n",
            "=================================================================\n",
            "Total params: 38,483\n",
            "Trainable params: 38,483\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFswQyMdifpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "044e74cb-595e-4bfd-a736-b3687b3c70ca"
      },
      "source": [
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# fit model\n",
        "model.fit(X, y, epochs=100, verbose=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            " - 0s - loss: 3.9614 - accuracy: 0.0290\n",
            "Epoch 2/100\n",
            " - 0s - loss: 3.9343 - accuracy: 0.0580\n",
            "Epoch 3/100\n",
            " - 0s - loss: 3.9059 - accuracy: 0.1304\n",
            "Epoch 4/100\n",
            " - 0s - loss: 3.8667 - accuracy: 0.1449\n",
            "Epoch 5/100\n",
            " - 0s - loss: 3.8034 - accuracy: 0.1884\n",
            "Epoch 6/100\n",
            " - 0s - loss: 3.6830 - accuracy: 0.1304\n",
            "Epoch 7/100\n",
            " - 0s - loss: 3.4994 - accuracy: 0.1014\n",
            "Epoch 8/100\n",
            " - 0s - loss: 3.3625 - accuracy: 0.0725\n",
            "Epoch 9/100\n",
            " - 0s - loss: 3.2911 - accuracy: 0.0725\n",
            "Epoch 10/100\n",
            " - 0s - loss: 3.2279 - accuracy: 0.0725\n",
            "Epoch 11/100\n",
            " - 0s - loss: 3.1737 - accuracy: 0.1014\n",
            "Epoch 12/100\n",
            " - 0s - loss: 3.1328 - accuracy: 0.1159\n",
            "Epoch 13/100\n",
            " - 0s - loss: 3.1029 - accuracy: 0.1159\n",
            "Epoch 14/100\n",
            " - 0s - loss: 3.0729 - accuracy: 0.1159\n",
            "Epoch 15/100\n",
            " - 0s - loss: 3.0551 - accuracy: 0.1304\n",
            "Epoch 16/100\n",
            " - 0s - loss: 3.0391 - accuracy: 0.1159\n",
            "Epoch 17/100\n",
            " - 0s - loss: 3.0241 - accuracy: 0.1594\n",
            "Epoch 18/100\n",
            " - 0s - loss: 3.0107 - accuracy: 0.1304\n",
            "Epoch 19/100\n",
            " - 0s - loss: 2.9949 - accuracy: 0.2174\n",
            "Epoch 20/100\n",
            " - 0s - loss: 2.9856 - accuracy: 0.1594\n",
            "Epoch 21/100\n",
            " - 0s - loss: 2.9846 - accuracy: 0.1014\n",
            "Epoch 22/100\n",
            " - 0s - loss: 2.9788 - accuracy: 0.0870\n",
            "Epoch 23/100\n",
            " - 0s - loss: 2.9528 - accuracy: 0.1594\n",
            "Epoch 24/100\n",
            " - 0s - loss: 2.9417 - accuracy: 0.1159\n",
            "Epoch 25/100\n",
            " - 0s - loss: 2.9480 - accuracy: 0.1159\n",
            "Epoch 26/100\n",
            " - 0s - loss: 2.9295 - accuracy: 0.1159\n",
            "Epoch 27/100\n",
            " - 0s - loss: 2.9105 - accuracy: 0.1304\n",
            "Epoch 28/100\n",
            " - 0s - loss: 2.8920 - accuracy: 0.1449\n",
            "Epoch 29/100\n",
            " - 0s - loss: 2.8746 - accuracy: 0.1449\n",
            "Epoch 30/100\n",
            " - 0s - loss: 2.8475 - accuracy: 0.1884\n",
            "Epoch 31/100\n",
            " - 0s - loss: 2.8297 - accuracy: 0.2899\n",
            "Epoch 32/100\n",
            " - 0s - loss: 2.8389 - accuracy: 0.2029\n",
            "Epoch 33/100\n",
            " - 0s - loss: 2.7953 - accuracy: 0.2464\n",
            "Epoch 34/100\n",
            " - 0s - loss: 2.8520 - accuracy: 0.1159\n",
            "Epoch 35/100\n",
            " - 0s - loss: 2.7972 - accuracy: 0.2029\n",
            "Epoch 36/100\n",
            " - 0s - loss: 2.8319 - accuracy: 0.1739\n",
            "Epoch 37/100\n",
            " - 0s - loss: 2.8394 - accuracy: 0.1594\n",
            "Epoch 38/100\n",
            " - 0s - loss: 2.7851 - accuracy: 0.1739\n",
            "Epoch 39/100\n",
            " - 0s - loss: 2.7619 - accuracy: 0.2029\n",
            "Epoch 40/100\n",
            " - 0s - loss: 2.7515 - accuracy: 0.2029\n",
            "Epoch 41/100\n",
            " - 0s - loss: 2.7305 - accuracy: 0.2174\n",
            "Epoch 42/100\n",
            " - 0s - loss: 2.7446 - accuracy: 0.2029\n",
            "Epoch 43/100\n",
            " - 0s - loss: 2.6915 - accuracy: 0.2319\n",
            "Epoch 44/100\n",
            " - 0s - loss: 2.6545 - accuracy: 0.2029\n",
            "Epoch 45/100\n",
            " - 0s - loss: 2.6455 - accuracy: 0.2174\n",
            "Epoch 46/100\n",
            " - 0s - loss: 2.6263 - accuracy: 0.2319\n",
            "Epoch 47/100\n",
            " - 0s - loss: 2.6827 - accuracy: 0.1884\n",
            "Epoch 48/100\n",
            " - 0s - loss: 2.6947 - accuracy: 0.1739\n",
            "Epoch 49/100\n",
            " - 0s - loss: 2.6158 - accuracy: 0.2319\n",
            "Epoch 50/100\n",
            " - 0s - loss: 2.6680 - accuracy: 0.2609\n",
            "Epoch 51/100\n",
            " - 0s - loss: 2.5809 - accuracy: 0.3043\n",
            "Epoch 52/100\n",
            " - 0s - loss: 2.5545 - accuracy: 0.2319\n",
            "Epoch 53/100\n",
            " - 0s - loss: 2.5105 - accuracy: 0.2899\n",
            "Epoch 54/100\n",
            " - 0s - loss: 2.5046 - accuracy: 0.2609\n",
            "Epoch 55/100\n",
            " - 0s - loss: 2.4685 - accuracy: 0.3333\n",
            "Epoch 56/100\n",
            " - 0s - loss: 2.5141 - accuracy: 0.3623\n",
            "Epoch 57/100\n",
            " - 0s - loss: 2.4576 - accuracy: 0.3623\n",
            "Epoch 58/100\n",
            " - 0s - loss: 2.4980 - accuracy: 0.2899\n",
            "Epoch 59/100\n",
            " - 0s - loss: 2.4434 - accuracy: 0.2899\n",
            "Epoch 60/100\n",
            " - 0s - loss: 2.4050 - accuracy: 0.3188\n",
            "Epoch 61/100\n",
            " - 0s - loss: 2.4587 - accuracy: 0.2464\n",
            "Epoch 62/100\n",
            " - 0s - loss: 2.3323 - accuracy: 0.3188\n",
            "Epoch 63/100\n",
            " - 0s - loss: 2.3989 - accuracy: 0.3043\n",
            "Epoch 64/100\n",
            " - 0s - loss: 2.2938 - accuracy: 0.3768\n",
            "Epoch 65/100\n",
            " - 0s - loss: 2.2991 - accuracy: 0.3333\n",
            "Epoch 66/100\n",
            " - 0s - loss: 2.2658 - accuracy: 0.3478\n",
            "Epoch 67/100\n",
            " - 0s - loss: 2.2393 - accuracy: 0.4348\n",
            "Epoch 68/100\n",
            " - 0s - loss: 2.2307 - accuracy: 0.3623\n",
            "Epoch 69/100\n",
            " - 0s - loss: 2.2218 - accuracy: 0.3768\n",
            "Epoch 70/100\n",
            " - 0s - loss: 2.1801 - accuracy: 0.3623\n",
            "Epoch 71/100\n",
            " - 0s - loss: 2.1356 - accuracy: 0.3623\n",
            "Epoch 72/100\n",
            " - 0s - loss: 2.1147 - accuracy: 0.4058\n",
            "Epoch 73/100\n",
            " - 0s - loss: 2.0868 - accuracy: 0.5072\n",
            "Epoch 74/100\n",
            " - 0s - loss: 2.0552 - accuracy: 0.4783\n",
            "Epoch 75/100\n",
            " - 0s - loss: 2.0398 - accuracy: 0.3768\n",
            "Epoch 76/100\n",
            " - 0s - loss: 2.0298 - accuracy: 0.4348\n",
            "Epoch 77/100\n",
            " - 0s - loss: 2.0198 - accuracy: 0.3623\n",
            "Epoch 78/100\n",
            " - 0s - loss: 2.0180 - accuracy: 0.3188\n",
            "Epoch 79/100\n",
            " - 0s - loss: 1.9478 - accuracy: 0.4058\n",
            "Epoch 80/100\n",
            " - 0s - loss: 1.9186 - accuracy: 0.4058\n",
            "Epoch 81/100\n",
            " - 0s - loss: 1.8938 - accuracy: 0.3913\n",
            "Epoch 82/100\n",
            " - 0s - loss: 1.8325 - accuracy: 0.4493\n",
            "Epoch 83/100\n",
            " - 0s - loss: 1.8496 - accuracy: 0.4928\n",
            "Epoch 84/100\n",
            " - 0s - loss: 1.8469 - accuracy: 0.4638\n",
            "Epoch 85/100\n",
            " - 0s - loss: 1.7726 - accuracy: 0.5362\n",
            "Epoch 86/100\n",
            " - 0s - loss: 1.7599 - accuracy: 0.5652\n",
            "Epoch 87/100\n",
            " - 0s - loss: 1.7361 - accuracy: 0.6232\n",
            "Epoch 88/100\n",
            " - 0s - loss: 1.7377 - accuracy: 0.5362\n",
            "Epoch 89/100\n",
            " - 0s - loss: 1.7968 - accuracy: 0.5072\n",
            "Epoch 90/100\n",
            " - 0s - loss: 1.6809 - accuracy: 0.6087\n",
            "Epoch 91/100\n",
            " - 0s - loss: 1.6576 - accuracy: 0.5942\n",
            "Epoch 92/100\n",
            " - 0s - loss: 1.6332 - accuracy: 0.5652\n",
            "Epoch 93/100\n",
            " - 0s - loss: 1.6102 - accuracy: 0.6087\n",
            "Epoch 94/100\n",
            " - 0s - loss: 1.5479 - accuracy: 0.6377\n",
            "Epoch 95/100\n",
            " - 0s - loss: 1.5750 - accuracy: 0.6232\n",
            "Epoch 96/100\n",
            " - 0s - loss: 1.5715 - accuracy: 0.6087\n",
            "Epoch 97/100\n",
            " - 0s - loss: 1.5211 - accuracy: 0.6377\n",
            "Epoch 98/100\n",
            " - 0s - loss: 1.5595 - accuracy: 0.6087\n",
            "Epoch 99/100\n",
            " - 0s - loss: 1.4898 - accuracy: 0.6377\n",
            "Epoch 100/100\n",
            " - 0s - loss: 1.5788 - accuracy: 0.5362\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0a643ad940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}